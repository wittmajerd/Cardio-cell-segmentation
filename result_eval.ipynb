{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wittd\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n",
      "c:\\Users\\wittd\\anaconda3\\Lib\\site-packages\\pytools\\persistent_dict.py:63: RecommendedHashNotFoundWarning: Unable to import recommended hash 'siphash24.siphash13', falling back to 'hashlib.sha256'. Run 'python3 -m pip install siphash24' to install the recommended hash.\n",
      "  warn(\"Unable to import recommended hash 'siphash24.siphash13', \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cupy implementation is not available. Make sure you have the right version of Cupy and CUDA installed.\n",
      "Optional dependecy Dask_image is not installed. Implementations using it will be ignored.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from src.utils import *\n",
    "from src.dataset import get_data_from_file, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/7_felev/szakdoga'\n",
    "\n",
    "runs = os.listdir(save_path)\n",
    "# remove wandb folder\n",
    "runs.remove('wandb')\n",
    "\n",
    "dataframes = {}\n",
    "aggregated_data = {}\n",
    "\n",
    "for run in runs:\n",
    "    run_path = os.path.join(save_path, run)\n",
    "    results = glob.glob(os.path.join(run_path, 'test_result*.json'))\n",
    "    \n",
    "    # List to hold all dictionaries for the current run\n",
    "    run_data = []\n",
    "    \n",
    "    for result in results:\n",
    "        with open(result, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            run_data.append(data)\n",
    "    \n",
    "    # Create a DataFrame for the current run\n",
    "    run_df = pd.DataFrame(run_data)\n",
    "\n",
    "    mean_df = run_df.mean().to_frame(name='mean')\n",
    "    std_df = run_df.std().to_frame(name='std')\n",
    "    \n",
    "    # Combine mean and std into a single DataFrame\n",
    "    aggregated_df = pd.concat([mean_df, std_df], axis=1)\n",
    "    \n",
    "    dataframes[run] = run_df\n",
    "    aggregated_data[run] = aggregated_df\n",
    "\n",
    "# Now dataframes contains the aggregated DataFrame for each run\n",
    "for run in runs:\n",
    "    print(run)\n",
    "    print(aggregated_data[run])\n",
    "    # print(dataframes[run].head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649.2377342347785 512.7229437467809\n"
     ]
    }
   ],
   "source": [
    "# calculating the high resoulution test cell sizes\n",
    "\n",
    "def calculate_test_cell_sizes():\n",
    "    path = 'C:/7_felev/data'\n",
    "    files = []\n",
    "    for root, dirs, files_ in os.walk(path):\n",
    "        for file in files_:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if file.endswith('.npz'):\n",
    "                files.append(file_path)\n",
    "\n",
    "    assert len(files) == 163, \"Dataset size should be 163\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "    files = np.random.permutation(files)\n",
    "\n",
    "    test_files = files[:33]\n",
    "    # print(test_files)\n",
    "    # return test_files\n",
    "\n",
    "    cell_sizes_label = []\n",
    "    for file in test_files:\n",
    "        bio, mask = get_data_from_file(file, 8)\n",
    "        # print(file, bio.shape, mask.shape)\n",
    "\n",
    "        # calculating the high resoulution test cell sizes\n",
    "        true_mask_int = mask.astype(np.int32)\n",
    "        labeled_label, num_cells_label = label(true_mask_int, return_num=True)\n",
    "\n",
    "        cell_sizes_label.extend([region.area for region in regionprops(labeled_label)])\n",
    "\n",
    "    scale = mask.shape[0] / 80\n",
    "    cell_sizes_label = pixel_to_micrometer(cell_sizes_label, scale)\n",
    "\n",
    "    avg_cell_size_label = np.mean(cell_sizes_label) if cell_sizes_label else 0\n",
    "    std_cell_size_label = np.std(cell_sizes_label) if cell_sizes_label else 0\n",
    "\n",
    "    return avg_cell_size_label, std_cell_size_label\n",
    "\n",
    "mean, std = calculate_test_cell_sizes()\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet8_len8_singleconv\n",
      "UNet_len1_doubleconv\n",
      "UNet_len8_doubleconv\n",
      "UNet_len8_singleconv\n"
     ]
    }
   ],
   "source": [
    "def replot(save_path, run):\n",
    "    config_path = os.path.join(save_path, run)\n",
    "    config = load_config(config_path)\n",
    "    testset = test_dataset(config)\n",
    "    test_loader = DataLoader(testset, batch_size=config['batch_size'], shuffle=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    for i in range(5):\n",
    "        run_path = os.path.join(config_path, f'run_{i+1}')\n",
    "        best_model_path = os.path.join(run_path, 'best_model.pth')\n",
    "        model = torch.jit.load(best_model_path)\n",
    "        plot_path = os.path.join(run_path, 'plots')\n",
    "\n",
    "        if config['tiling']:\n",
    "            plot_results_tiles(test_loader, model, device, plot_path, 'Test image', config)\n",
    "        else:\n",
    "            plot_results_image(test_loader, model, device, plot_path, 'Test image', config)\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "save_path = 'C:/7_felev/szakdoga'\n",
    "\n",
    "# print('UNet8_len8_singleconv')\n",
    "# replot(save_path, 'UNet8_len8_singleconv')\n",
    "# print('UNet_len1_doubleconv')\n",
    "# replot(save_path, 'UNet_len1_doubleconv')\n",
    "# print('UNet_len8_doubleconv')\n",
    "# replot(save_path, 'UNet_len8_doubleconv')\n",
    "# print('UNet_len8_singleconv')\n",
    "# replot(save_path, 'UNet_len8_singleconv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
